\section{Results} \label{results} 

\subsection{Studies using SVM}

In a study by \textcite{syaifullahMachineLearningDiagnosis2021} the data set was split into a training set (723 \gls{adni}), validation set (723 \gls{adni}) and four independent testing sets ( 519 \gls{aibl}, 592 Japan \gls{ADNI}, 69 \gls{miriad}, 128 \gls{oasis}). \gls{mci} subjects from \gls{adni} were split into stable and progressive \gls{mci}. Using the longitudinal information from the \gls{adni} study, the subjects that didn't progress to an \gls{AD} diagnosis during four or more years were labeled stable \gls{mci}. \gls{mci} subjects that met criteria given by ADNI \autocite{Petersen201} for \gls{AD} diagnosis within the duration of the \gls{adni} study were labeled progressive MCI. To train the model progressive MCI was considered as belonging to the \gls{AD} continuum and stable MCI not belonging to the continuum. Therefore, the final training set was 321 \gls{AD} continuum (179 AD, 142 pMCI) and 335 non-AD continuum (271 \gls{nc}, 64 sMCI). Fine tuning was done on the rest of the \gls{ADNI} set (322 AD continuum, 336 non AD continuum).


\gls{vbm} was used to normalize the data in a pre-processing step. To help with dimensionality multiple \gls{roi} instead of voxel-based were used as input vectors. A nonlinear kernel, \gls{rbf}, was used to find the optimal hyperplane. \gls{loocv} was applied to estimate the true error rate and reduce over fitting. Classifying observation was done by calculating the distance from the hyperplane which lead to a likelihood score of having \gls{AD}. A sigmoid function squashed the score into the range (0,1) and the threshold for the classification was set to 0,5
Tested independently on four different databases yielded accuracy ranging from \textit{88}\% - \textit{94,2\%}, sensitivity ranging from \textit{85,1\%} - \textit{97,8\%} and specificity \textit{88,4 \%} - \textit{90,8\%}.
For further comparison, ratings of two neuroradiologists as well as a second \gls{svm} trained with \gls{mmse} as additional input were used. Assisted by an automated technique to help with \gls{mri} image interpretations (i.e. \gls{vsrad}), the highest metrics achieved by the neuroradiologists were: accuracy of \textit{73\%}, sensitivity of \textit{72\%} and specificity of \textit{79\%}. On the other hand, the SVM trained with additional MMSE scores outperformed both the neuroradiologists and the SVM trained with MRI images only and achieved accuracy ranging from \textit{92,5}\% - \textit{100\%}, sensitivity ranging from \textit{93,1\%} - \textit{100\%} and specificity \textit{92,4\%} - \textit{100\%}. The SVM with MMSE scores performed especially well on the \gls{miriad} database with accuracy of \textit{100\%}, sensitivity of \textit{100\%} and specificity of \textit{100\%}. Performance measures achieved by MMSE scores on its own weren't analysed in their study. 






\textcite{akramifardEmphasisLearningFeatures2020} used a first of its kind method to increasing the accuracy of a trained \gls{svm} classifier. They did so by repeating the most important feature sets in the input vector therefore emphasizing them. The authors call this method emphasized learning. 
To train the model the data of 705 people (156 AD, 338 MCI and 211 NC) were taken from \gls{adni}. Testing and validating the model was done on the same data set. Pre-processing steps included realignment, smoothing, skull-stripping and spatial normalization. For feature extraction white and gray matter were segmented and \gls{vbm} was used to extract \gls{roi}s. The final feature vector included 132 features derived from \gls{MRI} images and 12 other features that consisted of \gls{mmse} score, personal information, \gls{csf} biomarkers and \gls{pet} voxel values. To evaluate and test the model \gls{kfold} (\textit{k = 10}) was performed. \gls{pca} with 25 principle components were used to extract the most valuable features and reduce dimensionality. These features were then repeated as input vector.  
The optimal amount of repetitions was achieved as soon as \gls{kfold} values became stable with additional repetitions not increasing or decreasing accuracy. For the classification task \gls{svm} was used with a lineal kernel. The decision to use a lineal kernel was made after comparing it to a non-linear \gls{rbf} that yielded no significant difference in terms of accuracy but was easier and faster to train. By reducing and repeating the data, the initial accuracy of \textit{95.54\%} was improved and achieved a maximum accuracy of \textit{98.81\%} after having the reduced data repeated five times as input. The maximum sensitivity was at \textit{98.52\%} after repeating the reduced data seven times. Specificity was the highest (\textit{99.21\%}) while using the reduced data without any repetitions. Furthermore the authors analysed the accuracy that was achieved using each group of data alone (personal information = \textit{60\%}, \gls{mmse} score = \textit{91,9 \%}, \gls{mri} data = \textit{86,8\%}, CSF biomarker = \textit{59,4\%}, PET data = \textit{62,5\%}).




With the intention of increasing generalizability of \gls{ML} models, \textcite{liPredictionClinicalBiomarker2020} used an age correction approach to help with classification. Age correction was performed using \gls{hcpa} data set, which consist of 272 healthy adults (146 women, 126 men with age \textit{62.7 +/- 16.8}). For testing and training  \gls{adni} (\textit{n = 400}) with 136 AD subjects and 268 healthy control were used. Further testing of generalization was done with an independent dataset of 66 participants (\textit{AD = 41, HC = 25)}. Spatial and intensity normalization, skull stripping and segmentation of grey and white matter were applied as pre-processing steps. In total, 314 features were extracted from \gls{mri} images (296 from brain surface, 16 \gls{roi}s, \gls{etiv}, \gls{wmsa}). For each feature, a linear regression with its cortical thickness (or volume for \gls{ROI}, \gls{etiv}, \gls{wmsa}) and age was performed on the \gls{hcpa} data set. Yielding \textit{314} different linear regression models, \textit{303} models were kept since features used in those model were significantly (\textit{p < 0.05}) correlated with age. Inputting age of individuals from the training data set \gls{adni} into these linear regression model yielded the difference in  predicted volume/thickness and actual volume/thickness of the features. These calculated residuals represent the features without the linear age effect and where used as input vector for the \gls{svm}. Optimization of models parameter and estimating the models performance was done with cross-validation. To separate the data a nonlinear Gaussian kernel was used. In \gls{adni} training set, controlling for age increased accuracy from \textit{96.29\%} to \textit{97.03\%} and sensitivity from \textit{91.91\%} to \textit{94.12\%} while specificity \textit{98.51\%} had no changes. Using the third independent data set for validation revealed lower accuracy, sensitivity and specificity of \textit{84.85\%}, \textit{85.36\%} and \textit{84\%}. The authors then trained a second \gls{svm} model using only individuals that were amyloid-$\beta$ positive (for \gls{AD} group) and amyloid-$\beta$ negative (for healthy control group). This second model that was trained with 300 observation (\gls{AD} = 119, HC = 181) displayed accuracy of \textit{84.85\%}, sensitivity of \textit{95.12\%} and specificity of \textit{68\%} while tested on the independent testing set. Furthermore, analysing the features used for training the authors concluded that volumes of hippocampus and amygdala had the highest classification power. 



A study done by \textcite{khatriEfficientCombinationSMRI2020a} trained two \gls{svm}s with 187 individuals from \gls{adni}. After pre-processing the data and extracting cortical thickness, surface area and gray matter volume as \gls{mri} features. Then, other modalities such as the \gls{apoe} genotyp, \gls{csf} biomarkers and \gls{mmse} score were combined into the feature vector. Using \gls{kfold} (\textit{k=10}) with filter and wrapper algorithms the author selected 60 most important features. These were used as input for the classifier. The authors compared 3 different classifiers:  \gls{elm}, a feed forward neural network with one hidden layer, \gls{svm} with linear kernal and a \gls{svm} with \gls{rbf} kernal. The classification task of \gls{AD} vs normal cognition was evaluated using 10-fold cross-validation. With an accuracy of \textit{93.50\%}, sensitivity of \textit{95.5\%} and specificity of \textit{90.58\%}, \gls{svm}-linear performed better than \gls{svm}-\gls{rbf} (\textit{91.33\%}, \textit{93.33\%}, \textit{87.57\%}). The \gls{elm} on the other hand, outperformed both \gls{svm}s with accuracy of \textit{97.31\%}, sensitivity of \textit{98.04\%} and specificity of \textit{96.28\%}. Furthermore, the authors analysed performance measurements while using the groups of feature separately (e.g. cortical thickness, surface area, volume, \gls{csf}, \gls{apoe} + \gls{mmse}) which provided much lower metrics.  




Emphasizing the importance of feature selection, \textcite{richhariyaDiagnosisAlzheimerDisease2020} propose a novel method termed \gls{uvsm-rfe}. This method adds the ability of using prior knowledge about the data's distribution for the feature selection process. Additionally, it attributes weights to every feature based on its importance within the classification task and eliminating features with low importance. The process of assigning weights and selecting features happens in recursive manner hence the name. Furthermore, the authors claim that since the distribution information is considered while eliminating features this can help with generalization and counteracts the greedy nature of \gls{svm} that mainly tries to maximize the margin (see \ref{Support Vector Machine}). GM, WM and \gls{csf} were extracted from 150 (\textit{AD = 50, MCI = 50, HC = 50}) \gls{mri}-images taken from \gls{adni}. To create distribution information, new data points were generated by averaging random data points from the training set. The optimal parameters for feature elimination were chosen with \gls{kfold}. A linear kernel was used to separate the classes. Assessing the models performance was done with an independently testing set consisting of 813 \gls{mri} images from \gls{adni} (\textit{AD = 187, MCI = 398, HC = 228}). The proposed method \gls{uvsm-rfe} scored an accuracy of \textit{89.2\%}, sensitivity of \textit{84.87\%} and specificity of \textit{93.13\%} while reducing tissue features by \textit{85\%}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5


\subsection{Studies using CNN}


%%%%%%%%%%%%%%%%%%%%%5
A plea for standardizing the different steps involved in classification with \gls{cnn} was made by \textcite{wenConvolutionalNeuralNetworks2020}, providing a open source framework to tackle concerns of biased evaluation, over fitting, reproducability and pre-processing problems. The framework focuses on reproducible evaluation of AD classification using \gls{DL} methods. It's an extension of their previously proposed framework that focuses on conventional \gls{ML} for AD classification using different modalities (e.g. \gls{pet}, \gls{mri}) \autocite{SAMPERGONZALEZ2018504}. 
Using their framework, the authors trained and compared multiple \gls{cnn} model as well as a linear \gls{svm}. The assessed models were trained and validated with \gls{adni} (\textit{n = 1255}) while varying the extend of the pre-processing techniques. Thereby, the author found that intensity rescaling was a crucial pre-processing step and without it the 3D \gls{cnn} dropped accuracy (from \textit{80\%} to \textit{50\%}) measured on the validation set. Other pre-processing steps (e.g skull-stripping, non-linear registration) had a small impact on accuracy. Therefore, the authors performed minimal pre-processing (e.g. bias field correction, inentisty rescaling and linear registration)  in all other \gls{cnn} models. 
Three separate test were done to asses performance using \gls{oasis} (\textit{n = 154}), \gls{aibl} (\textit{n = 598}) and a randomly selected subset of \gls{adni} (\textit{n = 200}) that was split before training the model. The highest accuracy (\textit{89\%}), measured as average from a \gls{kfold} (\textit{k=5}) from the \gls{adni} test set, was achieved by the 3D \gls{roi}-based \gls{cnn}. Linear \gls{svm} had the highest accuracy (\textit{88\%}) on the \gls{aibl} test set, followed by the 3D subject-level \gls{cnn} with an accuracy of \textit{86\%}. Finally, 3D \gls{roi}-based \gls{cnn} yielded the highest accuracy of \textit{73\%} tested on the \gls{oasis} test set. Sensitivity and specificity measurements weren't reported in their paper but are downloadable \autocite{wen_junhao_2019_3491003}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcite{yeeConstructionMRIBasedAlzheimer2021} trained a 3D subject-level \gls{cnn} which was tested for generalizability on four independent databases (subset of \gls{adni}, \gls{aibl}, \gls{oasis} and \gls{miriad}) amounting to \textit{7.902} images. Considering baseline and longitudinal information, images of subjects in the databases (except for \gls{miriad}) were categorized into seven groups with the aim of representing the continuum of \gls{AD} and differentiating clinical manifestation from pathophysiological brain changes (see table \ref{tab:strati} for subgroup descriptions). Three of those groups can be labelled as not related to \gls{AD} continuum since the subjects of those image didn't receive a \gls{AD} diagnosis during any follow up screenings. Images from the other four groups can be labelled as \gls{AD} related because the subjects progressed to \gls{AD} or already joined the cohort with the diagnosis.  



To train the model, they only included baseline and longitudinal images of stable \gls{nc} (\textit{423}) and stable \gls{dat} (\textit{330}) groups from \gls{adni}. Furthermore, data augmentation was applied to help with over fitting. Validating the model was done with 5-fold cross-validation on the remaining \gls{adni} subjects that weren't used for training. Pre-processing steps, including centering and reslicing the \gls{mri} images as well as intensity standardizing were applied to images from all databases with the goal of standardizing the images. The neural network itself consisted of 9 convulutional blocks, every block having a convulutional layer with instance normalization layer and an activation layer (ReLU). Pooling layer and a softmax layer was used as classification layers. The classification threshold was set to \textit{0.5} meaning scores above \textit{0.5} were classified as \gls{AD}. Metric obtained from cross-validating the training set were: accuracy of \textit{88.1\%}, sensitivity of \textit{88.3\%} and specificity of \textit{88.1\%}. The binary classification task of images (s\gls{dat} and s\gls{nc}) for \gls{aibl}, \gls{oasis} and \gls{miriad} yielded accuracy's of \textit{90.7\%}, \textit{91.9\%} and \textit{95.7\%}. In table \ref{tab:perf} performance metrics using all subgroup are provided.  Additionally, the authors used visualization techniques to compare whether the patterns used by the \gls{cnn} models were similar to brain structures related to \gls{AD}. This technique revealed that thalamus, hippocampus and ventricles are key areas the network used for the classification.



Hippocampus has often been studied in relation to \gls{AD} since it belongs to the first brain regions damaged by the pathological changes that come with \gls{AD} \autocite{liuMultimodelDeepConvolutional2020a}. Emphasizing the methodological problems while studying this \gls{roi} (e.g. accurate segmentation), \textcite{liuMultimodelDeepConvolutional2020a} built a \gls{DL} framework with two \gls{cnn} models. The first 3D \gls{cnn} model automatically segments the hippocampus and solves the classification task. A second 3D DenseNet model, a type of \gls{cnn},  uses the 3D patch generated by the first model to perform its own classification. At the end of both models, a \gls{fc} layer as well as a softmax layer is applied and performs a final classification combining all relevant learned features. The data set consisted of 449 randomly selected baseline \gls{mri} images of \gls{adni} subjects (\textit{96} AD, \textit{233} \gls{mci} and \textit{119} \gls{nc}). \gls{sst}, \gls{in} and \gls{ir} were used as pre-processing steps. 3D patches surrounding the hippocampus were used as input. Since softmax function deliver probability scores the threshold for the classification was set to \textit{0.5}. To address the over fitting problem, dropout layer were applied. Testing and training was done with \gls{kfold} (\textit{k = 5}). For performance measures \textit{10\%} of the training data was withhold as testing set that wasn't used for training the model. The first model achieved accuracy of \textit{80.1\%}, sensitivity of \textit{79.9\%} and specificity of \textit{80.3\%}. The 3D DenseNet model outperformed the first model with an accuracy of \textit{86.6\%}, sensitivity of \textit{79.4\%} and specificity of \textit{92.4\%}. The proposed framework which includes both CNN models achieved the best performance: \textit{88.9\%}, \textit{86.6\%} and \textit{90.8\%}.




Another study focusing on the hippocampus was done by \textcite{wangDenseCNNDenselyConnected2021}. The authors extracted the \gls{roi} of \textit{933} subjects (\textit{326} AD and \textit{607} CN) and excluded nearly \textit{5\%} because of problematic segmentation. \gls{in} was done as pre-processing step and data augmentation lead to a \textit{6} times larger training set (\textit{5222 subjects}) that was used to train a DenseCNN model which is a lightweight DL model with a total of \textit{243'090} parameters. Dropout layer were included to handle over fitting. Final layers were a \gls{fc} and softmax layer. Using a \gls{kfold} (\textit{k = 5}) average performance was: accuracy of \textit{89.1\%}, sensitivity of \textit{98.5\%} and specificity of \textit{85.2\%}.

\textcite{nanniComparisonTransferLearning2020} compared three different models: \gls{svm}, 3D \gls{cnn} trained from scratch and an ensemble of five transfer learned 2D \gls{cnn}. \textit{773} subjects (AD = \textit{137},  NC = \textit{162} and \gls{mci} =  \textit{474} ) were obtained from the \gls{adni} database. Multiple pre-processing steps were applied including \gls{sst}, \gls{ir} and segmentation. Whole brain \gls{mri} volume was used for all models. The authors provide a method for using 3D \gls{mri} volume as input for 2D \gls{cnn} model while preserving spatial structural information between subjects that normally gets compromised when the input is slice based. The 3D \gls{cnn} model that was trained from scratch performed badly, which was why the authors didn't consider it for further analysis. The other two model achieved accuracy of \textit{93.2\%} (\gls{svm}) and \textit{90.2\%} (2D-\gls{cnn}) classifying \gls{AD} vs. \gls{nc}. 







